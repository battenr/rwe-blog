---
ttitle: "P-Values and Power: Please Explain"
author: "Ryan Batten"
date: "2022-08-02"
categories: [P-Values, Hypothesis Tests]
image: "p-value.jpeg"
bibliography: p-value_references.bib
draft: true
---

# Overview

P-values are a term commonly heard in scientific literature, however often they are misconstrued, misunderstood or misinterpreted. The p in p-value stands for probability, as a lot of statistics begins with. What exactly does it tell us? Let's find out

## Formal Definitions

### Hypotheses

Hypotheses are the best place to start for any science experiment or project. A hypothesis is what you are wanting to know. First you need to start with your research question. For example, are people who love lollipops older than people who do not? To do this, formally in statistics, we need a *null hypothesis* ($H_0$) and an *alternative hypothesis* ($H_A$). We will use two abbreviations here: LL for lollipop lickers and NLL for not lollipop lickers. We want to know "Do lollipop lickers have more sore tongues than those who do not lick lollipops?"

Re-phrasing this in statistically terms, $H_0$ is that people do not have more sore tongues if they lick lollipops compared to if they do. The questions now is what is our alternative hypothesis? Well there are three options to choose from:

1.  We think LL have more sore tongues than NLL

2.  We think LL have less sore tongues than NLL

3.  We don't know, but we don't think they are the same!

1 and 2 are what are called *one-sided* hypothesis. A one-sided hypothesis, means you are assuming the difference is bigger or smaller. A two-sided hypothesis means we simply don't know! We will assume we don't know and use $p$ to denote the proportion of lollipop sore tongues.

$$
H_0: p_{LL-ST} = p_{NLL-ST}
$$

$$
H_A: p_{LL-ST} \neq p_{NLL-ST}
$$

Now, before we continue we need to review how okay we are with being wrong. Being wrong is okay, but there are two different types of being wrong.

### Type I and II Errors

A type I error, sometimes referred to as $\alpha$ error, is the error of saying something happened when it did not. For example, the error of me assuming you bought a balloon **when you did not**. A type II error, sometimes referred to as $\beta$ error, is the error of saying something did not happen **when you did**. Using our balloon example, me assuming you didn't buy a balloon when you did.

### Power

The power of a statistical test is the probability that it correctly rejects the null hypothesis [@gelman2014beyond]. It is tied to the type II error, through the below formula.

$$
Power = 1 - \beta
$$

Remember our lollipop example? For that it would be the probability that we can say lollipop lickers are not the same age as not lollipop lickers.

### Test Statistic

Alright, I know at this point I'm boring you. One last definition and then we can get to the good stuff. A test statistic is exactly what it sounds like. A statistic used for tests! What kind of tests you may ask? Hypothesis tests like we have above. Now, the test statistic in itself may follow a variety of distributions depending on the test. I'll leave distributions to another post.

Common test statistics include:

-   Z statistic

-   T statistic

-   F statistic

### P-Value

The probability of such an extreme value of the test statistic occuring if the null hypothesis were true is often called the **P Value @bland2015introduction.** Similarly, the significance level

### Significance Level

Remember $\alpha$ from before? The type I error is sometimes referred to as the significance level. The number that is picked for the type I error is usually 0.05, however it is completely arbitrary to pick 0.05. It could be 0.20 or 0.02.

::: callout-important
There is no such thing as more significant. It is either significant at the level that was pre-specified before the analysis or not. For example: a p-value of 0.01 is not **more** significant than a p-value of 0.05
:::

## Back to our Problem  {sec-prob=""}

Finally, after all those boring definitions we are back to where we started. How are we going to determine whether people who are lollipop lickers have more sore tongues? This requires us to do a bit more thinking to determine the right statistical tool for the toolbox.

Let's think about this question a bit more first. Lollipop lickers tend to be younger right? Do boys like lollipops more than girls? Let's assume that both of those things are true. We will want to *control* for both of those variables. Control in this sense, means adding the variable in the equation like below.

$$
ST = LL + age + sex
$$

Now, the type of regression we will use is a *generalized linear model (GLM)*. Generalized here just means that you can apply to almost any situation, hence general. Another post will cover the differences between GLMs and regular old regression (*OLS*).

## Data on Lollipop Lickers and Sore Tongues

Now we know our question, have our tool and want to find out the answer. What are we missing.....the most important thing of all! Data! Luckily, there is a database that collects such data. It has data on 422 people. Below are the summary statistics for our groups

```{r, include = FALSE}
set.seed(2022)

n.total = runif(1, min = 100, max = 500) # resulted in 422
n.st = runif(1, min = 0, max = 422) # 249
n.nst = 422-249

df.st = data.frame( # 181 sore tongues
  age = runif(n = 181, min = 5, max = 30), 
  sex = rbinom(n = 181, size = 1 , prob = 0.61), 
  ll = rbinom(n = 181, size = 1, prob = 0.80),
  group = 1
)

mean(df.st$age)
sd(df.st$age)

df.st %>% count(ll)
df.st %>% count(sex)

df.nst = data.frame( # 241
  age = runif(n = 241, min = 20, max = 80), 
  sex = rbinom(n = 241, size = 1 , prob = 0.23), 
  ll = rbinom(n = 241, size = 1, prob = 0.20),
  group = 0
)

mean(df.nst$age)
sd(df.nst$age)

df.nst %>% count(ll)
df.nst %>% count(sex)

df = rbind(df.st, df.nst)
```

+-----------------------------+---------------------+-------------------+
|                             | Sore Tongues        | Not Sore Tongues  |
|                             |                     |                   |
|                             | (n = 181)           | (n = 241)         |
+=============================+:===================:+:=================:+
| **Lollipop Lickers, n (%)** | 146 (80.7%)         | 60 (24.9%)        |
+-----------------------------+---------------------+-------------------+
| **Age, mean (SD)**          | 17.9 (7.30)         | 48.0 (17.8)       |
+-----------------------------+---------------------+-------------------+
| **Female, n (%)**           | 107 (59.1%)         | 52 (21.6%)        |
+-----------------------------+---------------------+-------------------+

## Analysis Time! 

Using our handy dandy formula from above @sec-prob, and our tool from our toolbox (GLM). Below are the results.

```{r, echo = FALSE}

library(tidyverse)
library(broom)

mod <- glm(
  formula = group ~ ll + age + sex, 
  family = binomial(link = "logit"),
  data = df
)

broom::tidy(mod)
```

## Now for the Interpretation of the P-Value

The test statistic for regression is defined by $\beta / SE(\beta)$. Beta here is the coefficient. For example, the test statistic for age is

## Normal-Distribution

To begin, we need to start with some data. Who doesn't love data right?

```{r, warning = FALSE, message = FALSE, echo = FALSE}

library(tidyverse)



df <- rnorm(1000, mean = 30, sd = 10) %>% as.data.frame()

df$x <- df$.

ggplot(data = df, mapping = aes(x = x) ) + 
  geom_density() +
  theme_minimal() 
  

```

## Issues with the P-Value

P-values are typically over emphasized. They are a piece of the puzzle, however they are not the whole puzzle.

### Type M & Type S Error

Often type I and type II errors are highlighted however type M and type S errors are important to note as well. A type S error is the probability of an estimate being in the wrong direction [@gelman2014beyond]. A type M error is the factor by which the magnitude of an effect might be overestimated [@gelman2014beyond].

Definitions are always great but an example helps to better understand. Without any further
