{
  "hash": "f596ebb2aad10aaa26b9e606bd19e800",
  "result": {
    "markdown": "---\ntitle: \"Collapsibility/Non-collapsibility\" \nsubtitle: \"TBD\"\nauthor: \"Ryan Batten\"\ndate: \"2023-06-08\"\ncategories: [OR, GLM, Collapsibility]\nbibliography: collapsible.bib\n# image : \"standards.png\"\ndraft: true\nformat: \n  html:\n    toc: true\n    toc-title: Contents\n    toc-location: right\n    toc-depth: 4\n    code-fold: true\n---\n\n\n## Measures of Effect \n\nEpidemiologists and clinical researchers use different metrics to quantify the relationship between the exposure and outcome. Commonly used measures include the risk ratio (RR), risk difference (RD), odds ratio (OR) and hazard ratio (HR). Each one of these has benefits and drawbacks, including the type of outcome (binary, continuous, time-to-event), how these can apply to other samples/populations (often referred to as transportability or portability) and collapsibility. For this post, we're going to focus on the last one.\n\n## Example time! \n\nRather than bore you with a bunch of jargon up front, it's always better to work through an example first (at least in my opinion) and then bore you with jargon (just kidding!....maybe...maybe not).\n\nLet's say that we have two animal types (turtles and lions) and whether they caught a ball (yes/no). There is also sometimes a zookeeper that is around. Now this zookeeper can throw the animals a ball, which makes a difference on if they catch it or not. \\\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nset.seed(123)\n\nn = 500\n\nanimal_type <- rbinom(n, size = 1, prob = 0.5) # 0 for turtle, 1 for lion\nzookeeper_present <- rbinom(n, size = 1, prob = 0.5) # 0 for absent, 1 for present\nball_catch <- rbinom(n, 1, plogis(-1 + 2*animal_type + zookeeper_present))\n\ndf <- data.frame(animal_type, zookeeper_present, ball_catch)\n```\n:::\n\n\nThe first thing to do is to look at our fancy pants data we have. Let's separate it by whether a zookeeper was present or not.\n\n|             | Ball Not Caught | Ball Caught  | **Total** |\n|-------------|-----------------|--------------|-----------|\n| **Turtle**  | 65              | 70           | **135**   |\n| **Lion**    | 13              | 110          | **123**   |\n| **Total**   | **78**          | **180**      | **258**   |\n\n: **Zookeeper Present**\n\n|             | Ball Not Caught  | Ball Caught  | **Total** |\n|-------------|------------------|--------------|-----------|\n| **Turtle**  | 95               | 35           | **130**   |\n| **Lion**    | 30               | 82           | **112**   |\n| **Total**   | 125              | 117          | **242**   |\n\n: **Zookeeper Absent**\n\n|            | Ball Not Caught | Ball Caught  | **Total** |\n|------------|-----------------|--------------|-----------|\n| **Turtle** | 160             | 105          | **265**   |\n| **Lion**   | 43              | 192          | **235**   |\n| **Total**  | **203**         | **197**      | **500**   |\n\n: **Overall**\n\nNow let's get down to some analysis using the odds ratio (OR). If we calculate the odds ratio for each of these tables, we'd find ORs of: 7.86 for when the zookeeper is present, 7.42 when the zookeeper is absent and 6.80 overall. You may be wondering why there is such a difference. Perhaps these are just different numbers and we should expect this? At first, you'd be tempted to think that it's just a difference and perhaps if we average them it'll fix it. However that's not the case, the weighted average of 7.86 and 7.42 won't give us 6.80. So what do we do? Maybe we'll try a GLM.\n\n## What if we use a GLM? \n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <- glm(ball_catch ~ animal_type, \n            family = binomial(link = \"logit\"), \n            data = df)\n\nfit2 <- glm(ball_catch ~ animal_type + zookeeper_present, \n            family = binomial(link = \"logit\"),\n            data = df)\n\nexp(coef(fit1)['animal_type'])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nanimal_type \n   6.803987 \n```\n:::\n\n```{.r .cell-code}\nexp(coef(fit2)['animal_type'])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nanimal_type \n   7.602132 \n```\n:::\n:::\n\n\nDammit, must be some sort of sorcery you blurt out with an exasperated look on your face. \"Gotta be confounding...or...some weird magical bias or...\". If you're thinking that, relax. It's a known \"issue\" (more on if it's an issue later), that happens with odds ratios as a measure. \\\n\\\nWhat is happening here is something called non-collapsibility.\n\n## What exactly do we mean by collapsible? \n\nGreenland and Pearl defined collapsibility as \"when an adjustment does not alter a measure, the measure is said to be collapsible over C or invariant with respect to the adjustment. Conversely, if an adjustment alters a measure the measure is said to be non-collapsible over C\" [@greenland2011].\n\nSo what exactly does this mean? Well it means that even when there is no confounding whether we include a covariate in our model matters for the magnitude of our treatment (if that covariate impacts the outcome) [@daniel2021]. The paper by Daniel et al., illustrates a good way to tell if we should expect a measure to be collapsible or not.\n\n::: callout-note\n## Bore you about statistics?\n\nIf you are actually interested in what I'm referring to, here's the nitty gritty (keep in mind it's a very, very brief summary). For GLMs, an important component is the link function. In the paper they highlight five: identity, log, logit, complementary log-log and probit. They use a function called the *characteristic collapsibility function* which can be used to explain the difference in collapsible vs noncollapsible measures. \\\n\\\n$$\ng_\\nu(.) = f^{-1}{f(.) + \\nu}\n$$\\\n\\\nThis shows that what is a super helpful property: not allowing models to predict probabilites outside the range of \\[0, 1\\]. To do this, the function needed to be bended. These bendy bits result in an inevitable consequence: noncollapsibility.\n:::\n\n## So what's the problem?\n\nAs Frank Harrell points out in his blog post, this isn't necessarily undesirable (link: https://www.fharrell.com/post/marg/). Any covariate adjustment will improve estimation and power over unadjusted marginal treatment effects. Another issue is that pooled marginal estimates are difficult to interpret. For example, who exactly does this estimate apply to? Yet another issue is that marginal ORs do not transport to populations with a different ratio than the sample you are analyzing.\n\nThere are differing views on the correct approach and boils down to opinion of the analyst. There is a great article by [@doi2022] about some considerations when using a OR vs RR, namely the portability across trials (essentially how can apply these results to another sample/population). The point of this point was to not advocate for or against a specific measure but rather to highlight a key point that needs considering when interpreting results: is this a marginal estimate or a conditional estimate?\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}