{
  "hash": "79064e61bfdd0ffb72d1d5166bbc233a",
  "result": {
    "markdown": "---\ntitle: \"Missing Data\" # November Post \nsubtitle: \"The Where's Waldo of Causal Inference\" # Titles are placeholders\nauthor: \"Ryan Batten\"\ndate: \"2023-11-26\"\ncategories: [Missing Data, MCAR, MAR, MNAR]\nbibliography: missing-data.bib\ndraft: true\nformat: \n  html:\n    code-fold: true\n---\n\n\n# Missing Data\n\nMissing data are inevitable when dealing with real-world data. Due to this, it's important to have a plan for dealing with missing data. There are tons of different methods that can be used for missing data but this post will focus on four different methods: multiple imputation, k nearest neighbour imputation, regression imputation and last observation carried forward. In order to make a valid causal inference we need to have an appropriate plan for what to do with this missing data.\n\nBefore we get started, we need to go over the different types of missing data mechanisms, arguably the most important aspect of dealing with missing data. Basically, what are the ways that data comes to be missing.\n\n# Missing Data Mechanisms\n\n\"How did this data end up becoming missing?\" is the best place to start. Was this just random? Or is there a reason? This can happen for a variety of reasons including the patient refusing to respond to a certain question, being lost to follow-up, investigator error or certain tests not being order. There are a myriad of reasons but these are commonly organized into three different types of data mechanisms: missing completely at random (MCAR), missing at random (MAR) and missing not a random (MNAR).\n\nEach one of these requires making different assumptions, which in turn needs different methods to deal with. Let's break down each one a little further. For each of these.\n\n## Missing Completely at Random (MCAR)\n\nData are considered to be \"missing completely at random\" if the probability of a variable being missing for a given subject, is independent from both observed and unobserved variables for that subject [@austin2021missing].\n\nMissing completely at random is the just that. The key word is \"completely\". This means that it has nothing to do with the other variables that we are interested in. Let's use an example\n\n## Missing at Random (MAR)\n\nData are considered to be \"missing at random\" if, after accounting for all the observed variables, the probability of a variable being missing is independent from the unobserved data [@austin2021missing].\n\n## Missing Not at Random (MNAR)\n\nData are considered to be \"missing not at random\" if, they are neither MCAR or MAR. But that's not super helpful, let's try again. Data are MNAR if the probability of being missing, even after accounting for all the observevd variables, is based on the value of the missing variable [@austin2021missing].\n\nAn example of MNAR wou\n\n::: callout-note\n## MAR vs MNAR\n\nUnfortunately, there is no way to test for MAR vs MNAR, so this needs to be based on expert knowledge [@austin2021missing].\n:::\n\n## Pirate Treasure?\n\nImagine that we have a collection of pirate treasure maps. The missing data mechanisms could be thought of like this:\\\n\\\n**MCAR**: Some maps are missing because they were randomly lost during a storm at sea\n\n**MAR**: Maps are missing for treasures buried in a haunted island because superstitious pirates (whose superstitions are recorded) avoid those places.\\\n\\\n**MNAR**: Maps are missing for the most valuabel treasures because the pirates who buried them never shared the locations, fearing theft, and their level of paranoia isn't recorded. (So the most lucrative treasures are missing)\n\n# So...what do we do?\n\nOnce we know, or think we know, what type of missing data mechanism we have we need to figure out how to deal with this! This post will go over five methods, although there a LOT more than that. These are just some common ones that I see/have come across in my field. Each section will cover: overview of what the method is, assumptions (what's required of the method), when to use it and then an example in R.\n\n::: callout-warning\n## Covariates vs Outcomes\n\nThis post focuses on imputation for covariates, rather than outcomes. The methods are the same, but the plausibility may be different for an outcome variable. Furthermore, it depends on the audience. For example, certain regulatory bodies may prefer several scenarios such as best-case and worst-case imputation.\n:::\n\n::: callout-important\n## An Introduction to Methods for Missingness\n\nThis is meant to be an introduction to some of these methods. A few of them shouldn't have much additional detail to learn about that, such as last observation carried forward or complete cases. However others, such as multiple imputation, there is a litany of information about them. For example, there are entire textbooks on multiple imputation.\n\nThe goal of this post is more to be an introduction to missingness, and help identify some potential scenarios to use the different methods while avoiding pitfalls.\n:::\n\n# Pirate Treasure Example\n\nLet's simulate some data for our pirate treasure example. We'll assume that\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\n# Simulate a dataset\nset.seed(123) # for reproducibility\n\nn = 322\n\n# Pirate Data\n\ndf <- data.frame(\n  pirate_id = 1:n, \n  treasure_value = runif(n = n, min = 1000, max = 5000), \n  haunted_island = rbinom(n = n, size = 1, prob = 0.5),\n  pirate_superstition = rbinom(n = n, size = 1, prob = 0.5)\n) \n\n# MCAR\n\n# Randomly select 50 observations\n\nmcar_indices <- sample(1:nrow(df), 50) # randomly select 20 indices\ndf$treasure_value_mcar <- df$treasure_value\ndf$treasure_value_mcar[mcar_indices] <- NA # set these values to NA\n\n\n\n# MAR (depends on the value of another variable)\ndf$treasure_value_mar <- df$treasure_value\nis_mar <- df$haunted_island & df$pirate_superstition > 0.5\ndf$treasure_value_mar[is_mar] <- NA\n\n# MNAR Variable \ndf$treasure_value_mnar <- df$treasure_value\nmnar_prob <- df$treasure_value / max(df$treasure_value) # higher value, higher chance of being NA\ndf$treasure_value_mnar[runif(nrow(df)) < mnar_prob] <- NA\n\n# View the data\nhead(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  pirate_id treasure_value haunted_island pirate_superstition\n1         1       2150.310              0                   0\n2         2       4153.221              1                   1\n3         3       2635.908              0                   1\n4         4       4532.070              0                   0\n5         5       4761.869              1                   0\n6         6       1182.226              0                   1\n  treasure_value_mcar treasure_value_mar treasure_value_mnar\n1            2150.310           2150.310                  NA\n2            4153.221                 NA                  NA\n3            2635.908           2635.908                  NA\n4                  NA           4532.070                  NA\n5            4761.869           4761.869            4761.869\n6            1182.226           1182.226            1182.226\n```\n:::\n\n```{.r .cell-code}\n# Writing a Function for Selecting Appropriate Data \n\ndf_missing <- function(type){\n  if(type == \"mcar\"){\n    df |> \n      dplyr::select(\n        pirate_id, \n        treasure_value, \n        haunted_island, \n        pirate_superstition,\n        treasure_value_mcar\n      )\n  } else if (type == \"mar\"){\n        df |> \n      dplyr::select(\n        pirate_id, \n        treasure_value, \n        haunted_island, \n        pirate_superstition,\n        treasure_value_mar\n      )\n  } else if (type == \"mnar\"){\n        df |> \n      dplyr::select(\n        pirate_id, \n        treasure_value, \n        haunted_island, \n        pirate_superstition,\n        treasure_value_mar\n      )\n  } else{\n    \"Error please select one of the types of missing data mechnanism (MCAR, MAR, MNAR)\"\n  }\n}\n```\n:::\n\n\n# Complete Cases (Exclude All Missing)\n\n## What is it?\n\n\"Let's just get rid of the missing data! Then our problem will be solved!\"...not quite. While getting rid of the missing data certainly is *a* way to deal with missing values, you are also losing good information. However, like any method, there is a time and place for it.\n\n## When to Use\n\nComplete case analysis can be valid when only the outcome variable is incomplete and we assume MAR [@austin2021missing], however when we are dealing with covariates there are several disadvantages to this approach.\n\nUnless the data are MAR, the estimated stats and regression coefficients may be biased [@austin2021missing]. Even if the data are MCAR, by reducing the sample size, we are reducing the precision (i.e., confidence intervals will be wider). Another problem is that by using\n\n## Example\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Note to self: maybe this should be MCAR? \n\ndf.mar <- df_missing(type = \"mar\") \n\ncc <- df.mar |> \n  drop_na()\n\nmean(df.mar$treasure_value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2995.293\n```\n:::\n\n```{.r .cell-code}\nmean(cc$treasure_value_mar)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3017.684\n```\n:::\n:::\n\n\nWe can see in this example, that removing all the missing values results in a difference of values. If you compare the datasets then you'll see the differences and the flaws in this. Futhermore, this can drastically reduce your dataset if you only keep the observations that has a value for every value (as a function of the number of variables in your dataset).\n\n## Considerations\n\nComplete case analysis can be convenient from a data quality point of view, however it can cause some issues. For example, is the missing data are MCAR the analysis will have reduced precision due to the reduced sample size but the observed data will not be biased [@jakobsen2017]. If the missing data are not MCAR, the estimate of the effect may be biased [@jakobsen2017].\n\nIt's also important to consider which patients are being removed and how many. Is this now the same target population that it was originally? Imagine if ended up removing 25% of our sample! How would that affect our generalizability?\\\n\\\nComplete cases can be used in the right context (i.e., if \\<5% of sample is missing and data is MCAR \\[RYAN ADD REF\\]) however it requires some careful thought.\n\n# Last Observation Carried Forward\n\n## What is it?\n\nLast observation carried forward (LOCF) is very much what it sounds like. We take the last value that was observed and use it.\n\n## When to Use\n\nLOCF assumes that the data is MCAR (REF?). If the data are MCAR, the absence of data is unrelated to the study question or the values of the missing data themselves. It can be quite useful when it is plausible, for example when we need to carry through the value of sex (male/female).\n\n## Example\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf.mcar <- df_missing(type = \"mar\")\n```\n:::\n\n\n## Considerations\n\nThe plausibility of LOCF needs to be considered. For example, if we are studying pirates and have two categories: monsters vs humans, we can safely assume that the monster will still be a monster. An example where this might be a problem is a lab value. Is a lab value that is 30 days prior okay? What about 60, 90 or 400?\n\nOther assumptions include:\n\n-   No dropout\n\n-   Stability of the condition over time\n\n# Mean Value Imputation\n\n## What is it?\n\nWe impute the missing values with the mean of the values that we do have. This is done to replace the missing values, but requires some assumptions.\n\n## When to Use\n\n## Example\n\n## Considerations\n\nMean value imputation is just what it sounds like. You replace the missing values with the mean. Now, this fairly straightforward but there are some\n\n## What is it? When to Use\n\nMean value imputation is where you...well impute\n\n## Assumptions\n\n## Example\n\n## Pros/Cons\n\nPro\n\n-   Easy to implement\n\n-   Quick\n\nCon\n\n-   Artifically reduces variation in the data [@austin2021missing]\n\n-   Ignores relationships with other variables [@austin2021missing], which is often true in practice\n\n# Condition mean Imputation (aka using Regression)\n\n## What is it? \n\nConditional mean imputation is very similar to\n\n## When to Use\n\n## Example\n\n## Considerations\n\n\"Conditional mean imputation\" is similar to mean imputation however, a regression model is used to impute a single value for each missing value [@austin2021missing].\n\n# Multiple Imputation\n\n## What is it?\n\n## When to Use\n\n## Example\n\n## Considerations\n\n# K Nearest Neighbour Imputation\n\n## What is it?\n\n## When to Use\n\n## Example\n\n## Considerations\n\nK nearest neighbour imputation is a mouthful. So let's break it down. Essentially, what happens is you match people to the closest person. Based on this, you assume that their value is the same as this \"closest\" person. Why K? Well it's doesn't have to just be one person, it could be a couple (RYAN: how does this work)\\>\n\n# Summary of Methods\n\nThese are a few of the missing data methods that you may come across, however there is a VAST number of methods for missing data. The key takeaway should be to consider these, regardless of the method:\n\n-   What kind of assumptions does it make? (i.e., MCAR, MNAR, MAR)\n\n-   What are the tradeoffs? For example, increase in data quality but decreased in precision and generalizibility? Or increase in precision but decrease in replicability?\n\n-   Practically speaking: is this the right use case for the audience? For example, a regulatory body may have different wants than an eighth grader wanting her help with analyzing her missing pets data.\n\nHope this blog post was useful as an introduction to five methods to start, but this is only the beginning! Happy missing data exploring!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}