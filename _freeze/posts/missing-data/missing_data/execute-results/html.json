{
  "hash": "968822a5f812586c1a2f6eccbc611bd4",
  "result": {
    "markdown": "---\ntitle: \"Missing Data\" # November Post \nsubtitle: \"The Where's Waldo of Causal Inference\" # Titles are placeholders\nauthor: \"Ryan Batten\"\ndate: \"2023-11-26\"\ncategories: [Missing Data, MCAR, MAR, MNAR]\nbibliography: missing-data.bib\ndraft: true\nformat: \n  html:\n    code-fold: true\n---\n\n\n# Missing Data\n\nMissing data are unavoidable when dealing data in general, but even more so with real-world data. Soooo it's important to have a plan on what to do! To make valid causal inferences, we need to have a solution for this data, so what options do we have? Well, there a BUNCH of different methods that can be used but this post will focus on introducing five:\n\n-   Complete Case\n\n-   Last Observation Carried Forward\n\n-   Mean Value Imputation\n\n-   Conditional Mean Imputation (aka using regression)\n\n-   Multiple Imputation\n\nBefore we dive into these exciting methods, first we need to go over the different types of missing data mechanisms. Arguably the most important aspect of dealing with missing data is figuring this part out.\n\n# Missing Data Mechanisms\n\n\"How did this data end up becoming missing?\" is essentially what we are asking. Was this just random? Or is there a reason? Data can go missing for a variety of reasons. Some examples: a patient refusing to respond to a certain question, being lost to follow-up, investigator error or certain tests not being order.\n\nThere are a myriad of reasons but these are commonly organized into three different types of missing data mechanisms: missing completely at random (MCAR), missing at random (MAR) and missing not a random (MNAR). Let's break down each one a little further.\n\n## Missing Completely at Random (MCAR)\n\nData are considered to be \"missing completely at random\" if the probability of a variable being missing for a given subject, is independent from both observed and unobserved variables for that subject [@austin2021missing].\n\nMissing completely at random is the just that. The key word is \"completely\". This means that it has nothing to do with the other variables that we are interested in. Let's use an example\n\n## Missing at Random (MAR)\n\nData are considered to be \"missing at random\" if, after accounting for all the observed variables, the probability of a variable being missing is independent from the unobserved data [@austin2021missing].\n\n## Missing Not at Random (MNAR)\n\nData are considered to be \"missing not at random\" if, they are neither MCAR or MAR. But that's not super helpful, let's try again. Data are MNAR if the probability of being missing, even after accounting for all the observevd variables, is based on the value of the missing variable [@austin2021missing].\n\nAn example of MNAR wou\n\n::: callout-note\n## MAR vs MNAR\n\nUnfortunately, there is no way to test for MAR vs MNAR, so this needs to be based on expert knowledge [@austin2021missing].\n:::\n\n## Pirate Treasure?\n\nImagine that we have a collection of pirate treasure maps. The missing data mechanisms could be thought of like this:\\\n\\\n**MCAR**: Some maps are missing because they were randomly lost during a storm at sea\n\n**MAR**: Maps are missing for treasures buried in a haunted island because superstitious pirates (whose superstitions are recorded) avoid those places.\\\n\\\n**MNAR**: Maps are missing for the most valuabel treasures because the pirates who buried them never shared the locations, fearing theft, and their level of paranoia isn't recorded. (So the most lucrative treasures are missing)\n\n# So...what do we do?\n\nOnce we know, or think we know, what type of missing data mechanism we have we need to figure out how to deal with this! This post will go over five methods, although there a LOT more than that. These are just some common ones that I see/have come across in my field. Each section will cover: overview of what the method is, assumptions (what's required of the method), when to use it and then an example in R.\n\n::: callout-warning\n## Covariates vs Outcomes\n\nThis post focuses on imputation for covariates, rather than outcomes. The methods are the same, but the plausibility may be different for an outcome variable. Furthermore, it depends on the audience. For example, certain regulatory bodies may prefer several scenarios such as best-case and worst-case imputation.\n:::\n\n::: callout-important\n## An Introduction to Methods for Missingness\n\nThis is meant to be an introduction to some of these methods. A few of them shouldn't have much additional detail to learn about that, such as last observation carried forward or complete cases. However others, such as multiple imputation, there is a litany of information about them. For example, there are entire textbooks on multiple imputation.\n\nThe goal of this post is more to be an introduction to missingness, and help identify some potential scenarios to use the different methods while avoiding pitfalls.\n:::\n\n# Pirate Treasure Example\n\nLet's simulate some data for our pirate treasure example. We'll assume that\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\n# Simulate a dataset\nset.seed(123) # for reproducibility\n\nn = 322\n\n# Pirate Data\n\ndf <- data.frame(\n  pirate_id = 1:n, \n  treasure_value = runif(n = n, min = 1000, max = 5000), \n  haunted_island = rbinom(n = n, size = 1, prob = 0.5),\n  pirate_superstition = rbinom(n = n, size = 1, prob = 0.5)\n) \n\n# MCAR\n\n# Randomly select 50 observations\n\nmcar_indices <- sample(1:nrow(df), 50) # randomly select 20 indices\ndf$treasure_value_mcar <- df$treasure_value\ndf$treasure_value_mcar[mcar_indices] <- NA # set these values to NA\n\n\n\n# MAR (depends on the value of another variable)\ndf$treasure_value_mar <- df$treasure_value\nis_mar <- df$haunted_island & df$pirate_superstition > 0.5\ndf$treasure_value_mar[is_mar] <- NA\n\n# MNAR Variable \ndf$treasure_value_mnar <- df$treasure_value\nmnar_prob <- df$treasure_value / max(df$treasure_value) # higher value, higher chance of being NA\ndf$treasure_value_mnar[runif(nrow(df)) < mnar_prob] <- NA\n\n# View the data\nhead(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  pirate_id treasure_value haunted_island pirate_superstition\n1         1       2150.310              0                   0\n2         2       4153.221              1                   1\n3         3       2635.908              0                   1\n4         4       4532.070              0                   0\n5         5       4761.869              1                   0\n6         6       1182.226              0                   1\n  treasure_value_mcar treasure_value_mar treasure_value_mnar\n1            2150.310           2150.310                  NA\n2            4153.221                 NA                  NA\n3            2635.908           2635.908                  NA\n4                  NA           4532.070                  NA\n5            4761.869           4761.869            4761.869\n6            1182.226           1182.226            1182.226\n```\n:::\n\n```{.r .cell-code}\n# Writing a Function for Selecting Appropriate Data \n\ndf_missing <- function(type){\n  if(type == \"mcar\"){\n    df |> \n      dplyr::select(\n        pirate_id, \n        treasure_value, \n        haunted_island, \n        pirate_superstition,\n        treasure_value_mcar\n      )\n  } else if (type == \"mar\"){\n        df |> \n      dplyr::select(\n        pirate_id, \n        treasure_value, \n        haunted_island, \n        pirate_superstition,\n        treasure_value_mar\n      )\n  } else if (type == \"mnar\"){\n        df |> \n      dplyr::select(\n        pirate_id, \n        treasure_value, \n        haunted_island, \n        pirate_superstition,\n        treasure_value_mar\n      )\n  } else{\n    \"Error please select one of the types of missing data mechnanism (MCAR, MAR, MNAR)\"\n  }\n}\n```\n:::\n\n\n# Complete Cases (Exclude All Missing)\n\n## What is it?\n\n\"Let's just get rid of the missing data! Then our problem will be solved!\"...not quite. While getting rid of the missing data certainly is *a* way to deal with missing values, you are also losing good information. However, like any method, there is a time and place for it.\n\n## When to Use\n\nComplete case analysis can be valid when only the outcome variable is incomplete and we assume MAR [@austin2021missing], however when we are dealing with covariates there are several disadvantages to this approach.\n\nUnless the data are MAR, the estimated stats and regression coefficients may be biased [@austin2021missing]. Even if the data are MCAR, by reducing the sample size, we are reducing the precision (i.e., confidence intervals will be wider). Another problem is that by using\n\n## Example\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Note to self: maybe this should be MCAR? \n\ndf.mar <- df_missing(type = \"mar\") \n\ncc <- df.mar |> \n  drop_na()\n\nmean(df.mar$treasure_value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2995.293\n```\n:::\n\n```{.r .cell-code}\nmean(cc$treasure_value_mar)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3017.684\n```\n:::\n:::\n\n\nWe can see in this example, that removing all the missing values results in a difference of values. If you compare the datasets then you'll see the differences and the flaws in this. Futhermore, this can drastically reduce your dataset if you only keep the observations that has a value for every value (as a function of the number of variables in your dataset).\n\n## Considerations\n\nComplete case analysis can be convenient from a data quality point of view, however it can cause some issues. For example, is the missing data are MCAR the analysis will have reduced precision due to the reduced sample size but the observed data will not be biased [@jakobsen2017]. If the missing data are not MCAR, the estimate of the effect may be biased [@jakobsen2017].\n\nIt's also important to consider which patients are being removed and how many. Is this now the same target population that it was originally? Imagine if ended up removing 25% of our sample! How would that affect our generalizability?\\\n\\\nComplete cases can be used in the right context (i.e., if \\<5% of sample is missing and data is MCAR \\[RYAN ADD REF\\]) however it requires some careful thought.\n\n# Last Observation Carried Forward\n\n## What is it?\n\nLast observation carried forward (LOCF) is very much what it sounds like. We take the last value that was observed and use it.\n\n## When to Use\n\nLOCF assumes that the data is MCAR (REF?). If the data are MCAR, the absence of data is unrelated to the study question or the values of the missing data themselves. It can be quite useful when it is plausible, for example when we need to carry through the value of sex (male/female).\n\n## Example\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Here we need to have multiple measurements per pirate\n\n# FROM CHATGPT\n\nn_pirates <- 10   # Number of unique pirates\nn_measurements <- 5  # Number of measurements per pirate\n\n# Create the data frame\ndf.locf <- expand.grid(\n  pirate_id = 1:n_pirates,\n  measurement_id = 1:n_measurements\n) %>%\n  mutate(\n    treasure_value = runif(n = n_pirates * n_measurements, min = 1000, max = 5000),\n    haunted_island = rbinom(n = n_pirates * n_measurements, size = 1, prob = 0.5),\n    pirate_superstition = rbinom(n = n_pirates * n_measurements, size = 1, prob = 0.5)\n  )\n\n# View the dataframe\nhead(df.locf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  pirate_id measurement_id treasure_value haunted_island pirate_superstition\n1         1              1       3342.268              0                   0\n2         2              1       1595.112              1                   0\n3         3              1       1716.238              0                   0\n4         4              1       2356.886              1                   1\n5         5              1       1735.608              1                   0\n6         6              1       2622.166              0                   1\n```\n:::\n\n```{.r .cell-code}\n# # MY CODE\n# \n# df.mcar <- df_missing(type = \"mcar\")\n# \n# # RYAN: NEED to ADD MORE ROWS, multiple per pirate_id\n# \n# df.locf <- df.mcar %>% \n#   group_by(pirate_id) %>% \n#   dplyr::mutate(\n#     treasure_value = ifelse(is.na(treasure_value_mcar), lag(treasure_value_mcar), treasure_value_mcar)\n#   )\n```\n:::\n\n\n## Considerations\n\nThe plausibility of LOCF needs to be considered. For example, if we are studying pirates and have two categories: monsters vs humans, we can safely assume that the monster will still be a monster. An example where this might be a problem is a lab value. Is a lab value that is 30 days prior okay? What about 60, 90 or 400?\n\nOther assumptions include:\n\n-   No dropout\n\n-   Stability of the condition over time\n\n# Mean Value Imputation\n\n## What is it?\n\nMean value imputation takes the mean of the values that we *do* have and uses this wherever there are missing values. As a side note, the mean is sometimes called the expected value in statistics.\n\n## When to Use\n\nYou probably guessed this already, but we can use it when we have a mean! So this can be used for any variable that has a mean (typically a continuous variable).\n\n## Example\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf.mcar <- df_missing(type = \"mcar\")\n\nmean(df.mcar$treasure_value_mcar, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2967.92\n```\n:::\n\n```{.r .cell-code}\ndf.mean.imputation <- df.mcar %>% \n  dplyr::mutate(\n    new_treasure_value = dplyr::case_when(\n      is.na(treasure_value_mcar) ~ mean(df.mcar$treasure_value_mcar, na.rm = TRUE),\n      !is.na(treasure_value_mcar) ~ treasure_value_mcar\n    )\n  )\n```\n:::\n\n\n## Considerations\n\nThis method is easy to implement and quick but there are some things we need to consider.\n\nMean value imputation is just what it sounds like. You replace the missing values with the mean. Now, this fairly straightforward but there are some assumptions that we need to consider. This method will give unbiased effects when the data is MCAR. It will lead to a decrease in the variability of the effect estimate though [@dziura2013, @austin2021missing]. It also ignores relationships with other variables, which may be the case [@austin2021missing]. It can be quite useful but needs to be used in the right circumstances.\n\n# Condition mean Imputation (aka using Regression)\n\n## What is it?\n\nConditional mean imputation is very similar to mean imputation but instead of using the mean, we'll use the conditional mean. How do we know the conditional mean? It's basically the result from our regression.\\\n\\\nBasically, you fit a regression model and then use this to predict what the value would be. A perk of this method is that you can fit a regression model including the variables that are associated with other variables.\n\n## When to Use\n\nWe can use this in similar scenarios to the mean value imputation.\n\n## Example\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf.mar <- df_missing(type = \"mar\")\n\nmar.regress <- glm(\n  treasure_value_mar ~ haunted_island + pirate_superstition, \n  family = gaussian(),\n  data = df.mar\n)\n\ntreasure_value_imputed = predict(mar.regress)\n\nregress.imputed <- df.mar %>%\n  mutate(\n    treasure_value_imputed = case_when(\n      is.na(treasure_value_mar) ~ predict(mar.regress, newdata = df.mar, type = \"response\"),\n      TRUE ~ treasure_value_mar\n    )\n  )\n\nmean(regress.imputed$treasure_value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2995.293\n```\n:::\n\n```{.r .cell-code}\nvar.og = sd(regress.imputed$treasure_value)\n\nmean(regress.imputed$treasure_value_imputed)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3046.162\n```\n:::\n\n```{.r .cell-code}\nvar.imputed = sd(regress.imputed$treasure_value_imputed)\n\nmean(regress.imputed$treasure_value_mar, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3017.684\n```\n:::\n\n```{.r .cell-code}\nsd(regress.imputed$treasure_value_mar, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1111.26\n```\n:::\n:::\n\n\nAs you can see, we are artificially reducing the variability in the variable. For example, 1121.7043222 is the original standard deviation, where as now the standard deviation is 962.1382697\n\n## Considerations\n\n\"Conditional mean imputation\" is similar to mean imputation however, a regression model is used to impute a single value for each missing value [@austin2021missing]. This will give an unbiased effect estimate when the missing data are MCAR or MAR [@dziura2013].\n\n# Multiple Imputation\n\n## What is it?\n\nMultiple imputation (MI) imputes multiple values for each missing value. It picks a value from a list of options, the distribution, and selects a value to be imputed. This results in multiple complete data sets where the missing value has been filled in with plausible values [@austin2021missing]. Each of these data sets is used to conduct the analysis, for example fitting a generalized linear model, then the results are pooled. For our case, we'll focus on the method known as multivariate imputation by chained equations (MICE). For more detail about it, I highly recommend @austin2021missing.\n\n## When to Use\n\n## Example\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mice) # package used for multiple imputation using chained equations\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'mice' was built under R version 4.3.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'mice'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:stats':\n\n    filter\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    cbind, rbind\n```\n:::\n\n```{.r .cell-code}\ndf.mcar <- df_missing(type = \"mcar\")\n\n# Perform MICE imputation\nmice_mod <- mice(df.mcar, m=5, maxit=50, meth='pmm', seed=500)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n iter imp variable\n  1   1\n  1   2\n  1   3\n  1   4\n  1   5\n  2   1\n  2   2\n  2   3\n  2   4\n  2   5\n  3   1\n  3   2\n  3   3\n  3   4\n  3   5\n  4   1\n  4   2\n  4   3\n  4   4\n  4   5\n  5   1\n  5   2\n  5   3\n  5   4\n  5   5\n  6   1\n  6   2\n  6   3\n  6   4\n  6   5\n  7   1\n  7   2\n  7   3\n  7   4\n  7   5\n  8   1\n  8   2\n  8   3\n  8   4\n  8   5\n  9   1\n  9   2\n  9   3\n  9   4\n  9   5\n  10   1\n  10   2\n  10   3\n  10   4\n  10   5\n  11   1\n  11   2\n  11   3\n  11   4\n  11   5\n  12   1\n  12   2\n  12   3\n  12   4\n  12   5\n  13   1\n  13   2\n  13   3\n  13   4\n  13   5\n  14   1\n  14   2\n  14   3\n  14   4\n  14   5\n  15   1\n  15   2\n  15   3\n  15   4\n  15   5\n  16   1\n  16   2\n  16   3\n  16   4\n  16   5\n  17   1\n  17   2\n  17   3\n  17   4\n  17   5\n  18   1\n  18   2\n  18   3\n  18   4\n  18   5\n  19   1\n  19   2\n  19   3\n  19   4\n  19   5\n  20   1\n  20   2\n  20   3\n  20   4\n  20   5\n  21   1\n  21   2\n  21   3\n  21   4\n  21   5\n  22   1\n  22   2\n  22   3\n  22   4\n  22   5\n  23   1\n  23   2\n  23   3\n  23   4\n  23   5\n  24   1\n  24   2\n  24   3\n  24   4\n  24   5\n  25   1\n  25   2\n  25   3\n  25   4\n  25   5\n  26   1\n  26   2\n  26   3\n  26   4\n  26   5\n  27   1\n  27   2\n  27   3\n  27   4\n  27   5\n  28   1\n  28   2\n  28   3\n  28   4\n  28   5\n  29   1\n  29   2\n  29   3\n  29   4\n  29   5\n  30   1\n  30   2\n  30   3\n  30   4\n  30   5\n  31   1\n  31   2\n  31   3\n  31   4\n  31   5\n  32   1\n  32   2\n  32   3\n  32   4\n  32   5\n  33   1\n  33   2\n  33   3\n  33   4\n  33   5\n  34   1\n  34   2\n  34   3\n  34   4\n  34   5\n  35   1\n  35   2\n  35   3\n  35   4\n  35   5\n  36   1\n  36   2\n  36   3\n  36   4\n  36   5\n  37   1\n  37   2\n  37   3\n  37   4\n  37   5\n  38   1\n  38   2\n  38   3\n  38   4\n  38   5\n  39   1\n  39   2\n  39   3\n  39   4\n  39   5\n  40   1\n  40   2\n  40   3\n  40   4\n  40   5\n  41   1\n  41   2\n  41   3\n  41   4\n  41   5\n  42   1\n  42   2\n  42   3\n  42   4\n  42   5\n  43   1\n  43   2\n  43   3\n  43   4\n  43   5\n  44   1\n  44   2\n  44   3\n  44   4\n  44   5\n  45   1\n  45   2\n  45   3\n  45   4\n  45   5\n  46   1\n  46   2\n  46   3\n  46   4\n  46   5\n  47   1\n  47   2\n  47   3\n  47   4\n  47   5\n  48   1\n  48   2\n  48   3\n  48   4\n  48   5\n  49   1\n  49   2\n  49   3\n  49   4\n  49   5\n  50   1\n  50   2\n  50   3\n  50   4\n  50   5\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Number of logged events: 1\n```\n:::\n\n```{.r .cell-code}\n# Fit a GLM to each imputed dataset\nglm_models <- with(mice_mod, glm(treasure_value_mcar ~ haunted_island + pirate_superstition, family = gaussian()))\n\n# Pool the results of the GLM models\npooled_results <- pool(glm_models)\n\n\n\n# Print the pooled results\nbroom::tidy(pooled_results) |> \n  select(term, estimate, std.error)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 term    estimate std.error\n1         (Intercept) 2982.709636  116.2663\n2      haunted_island  -40.054068  133.7189\n3 pirate_superstition    9.296319  133.6610\n```\n:::\n:::\n\n\n## Considerations\n\nThere are some considerations for using this. We need to decide if we think all the plausible values have been captured. MI only pulls from the existing values. So for example, if we have red, blue, yellow and green marbles in our population but only blue and green in our sample then red and yellow won't be imputed.\n\nWe also need to decide how large the number of imputed data sets are. There are many different ways to ascertain this but White et al. (ref from austin) suggested that as a rule of thumb it should be at least as large as the percentage of subjects with missing data. So if missingness is 22%, then we need at least 22 data sets.\n\n::: callout-note\n## MI is broad, this is an introduction\n\nMultiple imputation is one of those methods that has an extensive amount of literature on it. This was meant to be an introduction but there are full textbooks that focus on the topic.\n:::\n\n# Summary of Methods\n\nThese are a few of the missing data methods that you may come across, however there is a VAST number of methods for missing data. The key takeaway should be to consider these, regardless of the method:\n\n-   What kind of assumptions does it make? (i.e., MCAR, MNAR, MAR)\n\n-   What are the tradeoffs? For example, increase in data quality but decreased in precision and generalizibility? Or increase in precision but decrease in replicability?\n\n-   Practically speaking: is this the right use case for the audience? For example, a regulatory body may have different wants than an eighth grader wanting her help with analyzing her missing pets data.\n\nThis was just an introduction but there are a ton of great resources on each of these methods. There are also a bunch of other methods that are great to learn too (I'm currently still learning some of them so perhaps it will be a source of future posts!). This includes: K-Nearest Neighbour Matching, Predictive Mean Matching, Random Forest imputation and much more!\n\nHope this blog post was useful as an introduction to five methods to start, but this is only the beginning! Happy missing data exploring!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}