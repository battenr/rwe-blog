{
  "hash": "c2d0e90c255c83fdee8882cefaec54c4",
  "result": {
    "markdown": "---\ntitle: \"Missing Data\" # November Post \nsubtitle: \"The Where's Waldo of Causal Inference\" # Titles are placeholders\nauthor: \"Ryan Batten\"\ndate: \"2023-11-26\"\ncategories: [Missing Data, MCAR, MAR, MNAR]\nbibliography: missing-data.bib\nformat: \n  html:\n    code-fold: true\n---\n\n\n# Missing Data\n\nMissing data are unavoidable when dealing with data, especially with real-world data. So it's important to have a plan on what to do with missing data! To make valid causal inferences, we need to have a solution but what options do we have? A BUNCH! This post will focus on introducing five common methods:\n\n-   Complete Case\n\n-   Last Observation Carried Forward\n\n-   Mean Value Imputation\n\n-   Conditional Mean Imputation (aka using regression)\n\n-   Multiple Imputation\n\nBefore we dive into these, first we need to go over the different types of missing data mechanisms. Arguably the most important aspect of dealing with missing data is figuring this part out.\n\n# Missing Data Mechanisms\n\n\"How did this data end up becoming missing?\" is basically what we are trying to figure out. Was this just random? Or is there a reason? Data can go missing for a variety of reasons. A patient refusing to respond to a certain question, being lost to follow-up, investigator error or certain tests not being order to name just a few.\n\nTypically missing data are grouped into three types of missing data mechanisms: missing completely at random (MCAR), missing at random (MAR) and missing not a random (MNAR) [@austin2021missing] . Let's break down each one a little further.\n\n## Missing Completely at Random (MCAR)\n\nData are \"missing completely at random\" if the probability of a variable being missing is independent from both observed and unobserved variables for that person [@austin2021missing]. The key word here is \"completely\", implying that it has nothing to do with the other variables that we are interested in.\n\nLet's use an example. Imagine that we are taking a survey of a class of kindergarten children on what type of ice cream they ate. One day a mischievous puppy runs into the classroom and knocks over the box, and eats the surveys that fall out. The surveys that are missing are MCAR because it the dog didn't choose which ones to eat! It was just an accident.\n\n## Missing at Random (MAR)\n\nData are \"missing at random\" if the probability of a variable being missing, after accounting for **all** the observed variables is independent from the unobserved data [@austin2021missing]. So basically it can depend on the observed variables but has nothing to do with the unobserved variables.\n\nUsing our same example, imagine that kids who prefer mint or vanilla, decide to skip school and go to the beach. On those days when the teacher does the survey, the missing responses are more likely to be from kids who prefer those flavors. This would be MAR because it's dependent on the fact that these kids are more likely to be absent when it's hot.\n\n## Missing Not at Random (MNAR)\n\nData are considered to be \"missing not at random\" if, they are neither MCAR or MAR. But that's not super helpful, let's try again. Data are MNAR if the probability of being missing, even after accounting for all the observed variables, is based on the value of the missing variable [@austin2021missing].\n\nUsing our example again, imagine that some kids like a rare flavor like blueberry-cucumber. These kids are afraid that others might find it strange so whenever the survey is handed out they don't submit their surveys. This would be MNAR because it's directly related to the data itself.\n\n::: callout-note\n## MAR vs MNAR\n\nUnfortunately, there is no way to test for MAR vs MNAR, so this needs to be based on expert knowledge [@austin2021missing].\n:::\n\n# Pirate Treasure?\n\nIn order to illustrate how these data may look, we need to simulate some data! Imagine that we have a collection of pirate treasure maps. The missing data mechanisms could be thought of like this:\\\n\\\n**MCAR**: Some maps are missing because they were randomly lost during a storm at sea\n\n**MAR**: Maps are missing for treasures buried in a haunted island because superstitious pirates (whose superstitions are recorded) avoid those places.\\\n\\\n**MNAR**: Maps are missing for the most valuable treasures because the pirates who buried them never shared the locations, fearing theft, and their level of paranoia isn't recorded. (So the most lucrative treasures are missing)\n\nLet's simulate some data for our pirate treasure example. We can then use this to show how we might solve these different ways.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse) # Loading tidyverse package\n\nset.seed(123) # setting seed for reproducibility\n\nn = 322 # arbitrarily picked using runif(1, min = 100, max = 500)\n\n# Pirate Data\ndf <- data.frame(\n  pirate_id = 1:n, \n  treasure_value = runif(n = n, min = 1000, max = 5000), \n  haunted_island = rbinom(n = n, size = 1, prob = 0.5),\n  pirate_superstition = rbinom(n = n, size = 1, prob = 0.5)\n) \n\n# MCAR: Randomly select 50 observations\nmcar_indices <- sample(1:nrow(df), 50)\ndf$treasure_value_mcar <- df$treasure_value\ndf$treasure_value_mcar[mcar_indices] <- NA\n\n# MAR: Depends on the value of another variable\ndf$treasure_value_mar <- df$treasure_value\nis_mar <- df$haunted_island & df$pirate_superstition\ndf$treasure_value_mar[is_mar] <- NA\n\n# MNAR: Higher value, higher chance of being NA\ndf$treasure_value_mnar <- df$treasure_value\nmnar_prob <- df$treasure_value / max(df$treasure_value)\ndf$treasure_value_mnar[runif(nrow(df)) < mnar_prob] <- NA\n\nhead(df) # Viewing the data \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  pirate_id treasure_value haunted_island pirate_superstition\n1         1       2150.310              0                   0\n2         2       4153.221              1                   1\n3         3       2635.908              0                   1\n4         4       4532.070              0                   0\n5         5       4761.869              1                   0\n6         6       1182.226              0                   1\n  treasure_value_mcar treasure_value_mar treasure_value_mnar\n1            2150.310           2150.310                  NA\n2            4153.221                 NA                  NA\n3            2635.908           2635.908                  NA\n4                  NA           4532.070                  NA\n5            4761.869           4761.869            4761.869\n6            1182.226           1182.226            1182.226\n```\n:::\n\n```{.r .cell-code}\n# Function for Selecting Appropriate Data\ndf_missing <- function(type){\n  if(type == \"mcar\"){\n    df |> \n      dplyr::select(\n        pirate_id, \n        treasure_value, \n        haunted_island, \n        pirate_superstition,\n        treasure_value_mcar\n      )\n  } else if (type == \"mar\"){\n    df |> \n      dplyr::select(\n        pirate_id, \n        treasure_value, \n        haunted_island, \n        pirate_superstition,\n        treasure_value_mar\n      )\n  } else if (type == \"mnar\"){\n    df |> \n      dplyr::select(\n        pirate_id, \n        treasure_value, \n        haunted_island, \n        pirate_superstition,\n        treasure_value_mnar\n      )\n  } else{\n    stop(\"Error: Please select one of the types of missing data mechanisms (MCAR, MAR, MNAR)\")\n  }\n}\n```\n:::\n\n\n# So...what do we do?\n\nOnce we know, or make an assumption about, what type of missing data mechanism we have we need to figure out how to deal with this! This post will go over five methods, although there a LOT more than that. These are just some common ones that I see/have come across in my field (clinical epidemiology/biostatistics). Each section will cover what the method is, when to use it, an example and some considerations. Let's get started!\n\n::: callout-warning\n## Covariates vs Outcomes\n\nThis post focuses on imputation for covariates, rather than outcomes. The methods are the same, but the plausibility may be different for an outcome variable. Furthermore, it depends on the audience. For example, certain regulatory bodies may prefer several scenarios such as best-case and worst-case imputation.\n:::\n\n::: callout-important\n## An Introduction to Methods for Missingness\n\nThis is meant to be an introduction to some of these methods. A few of them shouldn't have much additional detail to learn about (i.e., complete cases) however others, such as multiple imputation, have a litany of information about them. For example, there are entire textbooks on multiple imputation.\n\nThe goal of this post is more to be an introduction to missingness, and help identify some potential scenarios to use the different methods while avoiding potential pitfalls.\n:::\n\n# Complete Cases (Exclude All Missing)\n\n## What is it?\n\n\"Let's just get rid of the missing data! Then our problem will be solved!\"...not quite. While getting rid of the missing data certainly is *a* way to deal with missing values, you are also losing good information. However, like any method, there is a time and place for it.\n\n## When to Use\n\nComplete case analysis can be valid if we assume that the data are MAR [@austin2021missing]. It also depends on how much missing data we have, and the corresponding reduction in sample size. If the missing data is small, for example less than 5%, this is a different situation than if there is 30% missingness.\n\n## Example\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf.mar <- df_missing(type = \"mar\") # selecting mar data\n\ncc <- df.mar |> \n  drop_na()\n\nmean(df.mar$treasure_value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2995.293\n```\n:::\n\n```{.r .cell-code}\nmean(cc$treasure_value_mar)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3017.684\n```\n:::\n:::\n\n\n## Considerations\n\nComplete case analysis can be convenient from a data quality point of view, however it can cause some issues. By not imputing any values, we are only using the \"observed\" values. This might seem beneficial but it can cause problems. Firstly, the estimated statistics and regression coefficients may be biased unless the data is MAR [@austin2021missing]. Secondly, there will be reduced precision (aka wider confidence intervals) because there is a reduction in sample size.\n\nIt's also important to consider which patients are being removed and how many. Is this now the same target population that it was originally? Imagine if we ended up removing 25% of our sample! How would that affect our generalizability? This might change our target population.\n\n# Last Observation Carried Forward\n\n## What is it?\n\nLast observation carried forward (LOCF) is very much what it sounds like. We take the last value that was observed and use it.\n\n## When to Use\n\nLOCF is used when there is longitudinal data, and it is assumed that it's plausible. For example, if we need to carry through the value of sex (male/female). If there is missingness for this data but it is available at a previous encounter, then we can assume it's the same.\n\n## Example\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Here we need to have multiple measurements per pirate\n\nn_pirates <- 10   # Number of unique pirates\nn_measurements <- 5  # Number of measurements per pirate\n\n# Create the data frame\ndf.locf <- expand.grid(\n  pirate_id = 1:n_pirates,\n  measurement_id = 1:n_measurements\n) %>%\n  mutate(\n    treasure_value = runif(n = n_pirates * n_measurements, min = 1000, max = 5000),\n    haunted_island = rbinom(n = n_pirates * n_measurements, size = 1, prob = 0.5),\n    pirate_superstition = rbinom(n = n_pirates * n_measurements, size = 1, prob = 0.5)\n  )\n\n\n\nmcar_indices <- sample(1:nrow(df.locf), 15) # randomly select 15 indices\ndf.locf$treasure_value_mcar <- df.locf$treasure_value\ndf.locf$treasure_value_mcar[mcar_indices] <- NA # set these values to\n\n# View the dataframe\n\ndf.locf %>% select(pirate_id, measurement_id, treasure_value_mcar) %>% \n  arrange(pirate_id, measurement_id)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   pirate_id measurement_id treasure_value_mcar\n1          1              1                  NA\n2          1              2            4811.364\n3          1              3            4478.129\n4          1              4            2864.015\n5          1              5            4792.268\n6          2              1                  NA\n7          2              2                  NA\n8          2              3            1243.352\n9          2              4                  NA\n10         2              5            1344.689\n11         3              1            1716.238\n12         3              2            3449.500\n13         3              3            1939.598\n14         3              4            1948.792\n15         3              5                  NA\n16         4              1            2356.886\n17         4              2            2854.295\n18         4              3            4972.062\n19         4              4            1932.959\n20         4              5            3889.595\n21         5              1                  NA\n22         5              2            2418.918\n23         5              3            3712.791\n24         5              4            1922.614\n25         5              5            4688.018\n26         6              1            2622.166\n27         6              2            4529.692\n28         6              3                  NA\n29         6              4            1246.905\n30         6              5            3455.364\n31         7              1            3454.238\n32         7              2                  NA\n33         7              3            2509.240\n34         7              4            2988.474\n35         7              5            1643.866\n36         8              1                  NA\n37         8              2                  NA\n38         8              3            2844.736\n39         8              4                  NA\n40         8              5            1731.763\n41         9              1            4294.102\n42         9              2                  NA\n43         9              3                  NA\n44         9              4            4032.742\n45         9              5            3920.734\n46        10              1            2495.928\n47        10              2            1860.267\n48        10              3                  NA\n49        10              4                  NA\n50        10              5            3358.103\n```\n:::\n:::\n\n\n## Considerations\n\nThe plausibility of LOCF needs to be considered. For example, if we are studying monsters and human, we can safely assume that the monster will still be a monster. Would this be true for the number of planets that a monster has been too? What about a lab value? Is a lab value stable at 30 days? What about 60, 90 or 400? This becomes a balance between what's clinical plausible and the reduction in sample size (if a shorter time window, might be more plausible but the last value might be further away than that).\n\n# Mean Value Imputation\n\n## What is it?\n\nMean value imputation takes the mean of the values that we *do* have and uses this wherever there are missing values. As a side note, the mean is sometimes called the expected value in statistics.\n\n## When to Use\n\nYou probably guessed this already, but we can use it when we have a mean! So this can be used for any variable that has a mean (typically a continuous variable). If the data are MCAR then the effect should be unbiased [@dziura2013].\n\n## Example\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf.mcar <- df_missing(type = \"mcar\")\n\ndf.mean.imputation <- df.mcar %>% \n  dplyr::mutate(\n    new_treasure_value = dplyr::case_when(\n      is.na(treasure_value_mcar) ~ mean(df.mcar$treasure_value_mcar, na.rm = TRUE),\n      !is.na(treasure_value_mcar) ~ treasure_value_mcar\n    )\n  )\n```\n:::\n\n\n## Considerations\n\nThis method is easy to implement and quick but there are some things we need to consider. First, the effect should be unbiased however the standard errors aren't necessarily. This is due to this method artificially reducing the variation in the data set [@austin2021missing]. It also ignores relationships with other variables which be might be true, but the plausibility of this needs to be considered [@austin2021missing]. These imputed values end up being treated as equal to the values that aren't missing [@austin2021missing], which may be incorrect since we know the observed values were recorded and not imputed.\n\n# Condition mean Imputation (aka using Regression)\n\n## What is it?\n\nConditional mean imputation is very similar to mean imputation but instead of using the mean, we'll use the conditional mean. How do we know the conditional mean? By predicting the result based on a model that we've fit to the data that we *do* have.\n\n## When to Use\n\nWe can use this in similar scenarios to the mean value imputation. When the data is MCAR or MAR the effects are expected to be unbiased [@dziura2013]. This method can incorporate relationships with other variables, which is an advantage over mean value imputation.\n\n## Example\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf.mar <- df_missing(type = \"mar\")\n\nmar.regress <- glm(\n  treasure_value_mar ~ haunted_island + pirate_superstition, \n  family = gaussian(),\n  data = df.mar\n)\n\ntreasure_value_imputed = predict(mar.regress)\n\nregress.imputed <- df.mar %>%\n  mutate(\n    treasure_value_imputed = case_when(\n      is.na(treasure_value_mar) ~ predict(mar.regress, newdata = df.mar, type = \"response\"),\n      TRUE ~ treasure_value_mar\n    )\n  )\n\nmean(regress.imputed$treasure_value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2995.293\n```\n:::\n\n```{.r .cell-code}\nvar.og = sd(regress.imputed$treasure_value)\n\nmean(regress.imputed$treasure_value_imputed)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3046.162\n```\n:::\n\n```{.r .cell-code}\nvar.imputed = sd(regress.imputed$treasure_value_imputed)\n\nmean(regress.imputed$treasure_value_mar, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3017.684\n```\n:::\n\n```{.r .cell-code}\nsd(regress.imputed$treasure_value_mar, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1111.26\n```\n:::\n:::\n\n\n## Considerations\n\nThis method can artificially amplify the multivariate relationship in the data [@austin2021missing]. For example, if we assume that age is related to our covariate then we end up imputing based on the values of age (which may not be the case). These imputed values end up being treated as equal to the values that aren't missing [@austin2021missing], which may be incorrect since we know the observed values were recorded and not imputed.\n\n# Multiple Imputation\n\n## What is it?\n\nMultiple imputation (MI) imputes a value for each missing value. It picks a value from a list of options, aka the distribution, and imputes it. This creates one data set. This is then done again, and again until there are multiple complete datasets where the missing value has been filled in using plausible values [@austin2021missing]. Each of these data sets is used to conduct the analysis, for example fitting a generalized linear model, then the results are pooled. For our case, we'll focus on the method known as multivariate imputation by chained equations (MICE). For more detail about it, I highly recommend @austin2021missing.\n\n## When to Use\n\nMI, based on @austin2021missing, can be used when the data are assumed to be MCAR or MAR. The methods can be modified if the data is thought to be MNAR [@van2018flexible]. This method can be used when it's assumed that all the plausible values have been captured for the variable of interest.\n\n## Example\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mice) # package used for multiple imputation using chained equations\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'mice' was built under R version 4.3.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'mice'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:stats':\n\n    filter\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    cbind, rbind\n```\n:::\n\n```{.r .cell-code}\ndf.mcar <- df_missing(type = \"mcar\")\n\n# Performing the imputation\n\nmice_mod <- mice(df.mcar, m=5, maxit=50, meth='pmm', seed=500)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n iter imp variable\n  1   1\n  1   2\n  1   3\n  1   4\n  1   5\n  2   1\n  2   2\n  2   3\n  2   4\n  2   5\n  3   1\n  3   2\n  3   3\n  3   4\n  3   5\n  4   1\n  4   2\n  4   3\n  4   4\n  4   5\n  5   1\n  5   2\n  5   3\n  5   4\n  5   5\n  6   1\n  6   2\n  6   3\n  6   4\n  6   5\n  7   1\n  7   2\n  7   3\n  7   4\n  7   5\n  8   1\n  8   2\n  8   3\n  8   4\n  8   5\n  9   1\n  9   2\n  9   3\n  9   4\n  9   5\n  10   1\n  10   2\n  10   3\n  10   4\n  10   5\n  11   1\n  11   2\n  11   3\n  11   4\n  11   5\n  12   1\n  12   2\n  12   3\n  12   4\n  12   5\n  13   1\n  13   2\n  13   3\n  13   4\n  13   5\n  14   1\n  14   2\n  14   3\n  14   4\n  14   5\n  15   1\n  15   2\n  15   3\n  15   4\n  15   5\n  16   1\n  16   2\n  16   3\n  16   4\n  16   5\n  17   1\n  17   2\n  17   3\n  17   4\n  17   5\n  18   1\n  18   2\n  18   3\n  18   4\n  18   5\n  19   1\n  19   2\n  19   3\n  19   4\n  19   5\n  20   1\n  20   2\n  20   3\n  20   4\n  20   5\n  21   1\n  21   2\n  21   3\n  21   4\n  21   5\n  22   1\n  22   2\n  22   3\n  22   4\n  22   5\n  23   1\n  23   2\n  23   3\n  23   4\n  23   5\n  24   1\n  24   2\n  24   3\n  24   4\n  24   5\n  25   1\n  25   2\n  25   3\n  25   4\n  25   5\n  26   1\n  26   2\n  26   3\n  26   4\n  26   5\n  27   1\n  27   2\n  27   3\n  27   4\n  27   5\n  28   1\n  28   2\n  28   3\n  28   4\n  28   5\n  29   1\n  29   2\n  29   3\n  29   4\n  29   5\n  30   1\n  30   2\n  30   3\n  30   4\n  30   5\n  31   1\n  31   2\n  31   3\n  31   4\n  31   5\n  32   1\n  32   2\n  32   3\n  32   4\n  32   5\n  33   1\n  33   2\n  33   3\n  33   4\n  33   5\n  34   1\n  34   2\n  34   3\n  34   4\n  34   5\n  35   1\n  35   2\n  35   3\n  35   4\n  35   5\n  36   1\n  36   2\n  36   3\n  36   4\n  36   5\n  37   1\n  37   2\n  37   3\n  37   4\n  37   5\n  38   1\n  38   2\n  38   3\n  38   4\n  38   5\n  39   1\n  39   2\n  39   3\n  39   4\n  39   5\n  40   1\n  40   2\n  40   3\n  40   4\n  40   5\n  41   1\n  41   2\n  41   3\n  41   4\n  41   5\n  42   1\n  42   2\n  42   3\n  42   4\n  42   5\n  43   1\n  43   2\n  43   3\n  43   4\n  43   5\n  44   1\n  44   2\n  44   3\n  44   4\n  44   5\n  45   1\n  45   2\n  45   3\n  45   4\n  45   5\n  46   1\n  46   2\n  46   3\n  46   4\n  46   5\n  47   1\n  47   2\n  47   3\n  47   4\n  47   5\n  48   1\n  48   2\n  48   3\n  48   4\n  48   5\n  49   1\n  49   2\n  49   3\n  49   4\n  49   5\n  50   1\n  50   2\n  50   3\n  50   4\n  50   5\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Number of logged events: 1\n```\n:::\n\n```{.r .cell-code}\n# Fitting a GLM to each imputed dataset. For this case, imagine that haunted_island \n# is the outcome \n\nglm_models <- with(mice_mod, glm(haunted_island ~ treasure_value_mcar + pirate_superstition, family = binomial()))\n\n# Pooling the results together \n\npooled_results <- pool(glm_models)\n\n# Print the pooled results\nbroom::tidy(pooled_results) |> \n  select(term, estimate, std.error)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 term      estimate   std.error\n1         (Intercept)  1.283701e-01 0.370735275\n2 treasure_value_mcar -3.340088e-05 0.000110922\n3 pirate_superstition -1.764281e-01 0.242919776\n```\n:::\n:::\n\n\n## Considerations\n\nThere are some considerations for using this. We need to decide if we think all the plausible values have been captured. MI only pulls from the existing values. So for example, if we have red, blue, yellow and green marbles in our population but only blue and green in our sample then red and yellow won't be imputed.\n\nWe also need to decide how large the number of imputed data sets are. There are many different ways to ascertain this. @white2011multiple suggested that as a rule of thumb it should be at least as large as the percentage of subjects with missing data. So if missingness is 22%, then we need at least 22 data sets.\n\n::: callout-note\n## MI is broad, this is an introduction\n\nMultiple imputation is one of those methods that has an extensive amount of literature on it. This was meant to be an introduction but there are full textbooks that focus on the topic.\n:::\n\n# Summary of Methods\n\nThese are a few of the missing data methods that you may come across, however there is a VAST number of methods for missing data. The key takeaway should be to consider these, regardless of the method:\n\n-   What kind of assumptions are required? (i.e., MCAR, MNAR, MAR)\n\n-   What are the tradeoffs? For example, increase in data quality but decreased in precision and generalizibility? Or increase in precision but decrease in replicability?\n\n-   Practically speaking: is this the right use case for the audience? For example, a regulatory body may have different wants than an eighth grader wanting her help with analyzing her missing pets data.\n\nThis was just an introduction but there are a ton of great resources on each of these methods! There are also a bunch of other methods that are great to learn too (I'm currently still learning some of them so perhaps it will be a source of future posts!). This includes: K-Nearest Neighbour Matching, Predictive Mean Matching, Random Forest imputation and much more!\n\nHopefully this blog post was useful as an introduction to five methods to start, but this is only the beginning! Happy missing data exploring!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}