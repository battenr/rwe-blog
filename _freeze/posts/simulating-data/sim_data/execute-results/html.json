{
  "hash": "23989fb8b3204efd5bab8d621bcf3ab8",
  "result": {
    "markdown": "---\ntitle: \"Mastering Statistics Through Make-Believe\" \nsubtitle: \"Simulating Data in R\"\nauthor: \"Ryan Batten\"\ndate: \"2023-09-30\"\ncategories: [Simulating Data]\nbibliography: sim_data.bib\nimage : sim_data.jpg\nformat: \n  html:\n    toc: true\n    toc-title: Contents\n    toc-location: right\n    toc-depth: 4\n    code-fold: true\n---\n\n\n## Why Simulate Data?\n\nSimulating data is something that I've learned since graduating from my masters. It's helped me tremendously with comparing methods and proving concepts to me. It's also helped me improve my statistics knowledge.\n\nI wanted to write this post to help anyone else who isn't familiar with simulating data. Personally, I like to always see examples, below are a few:\n\n-   Demonstrating bias by including/excluding a variable (confounder, collider, etc)\n\n-   Comparing different methods (1:1 matching vs IPTW, etc)\n\n-   Understand data generating mechanisms\n\nEnough about how it's helpful, how do we do it?!\n\n::: callout-note\n## R Code\n\nI primarily use R for coding, so this post focuses on using R. However, the methodology applies to whatever program you use for analysis. If you prefer to use MS Excel, you can do this using Excel as well, although it may not be the easiest.\\\n\\\nIf you're looking to learn R, I can't recommend R for Data Science by Hadley Wickham enough (plus it's free!)\n:::\n\n## How to Simulate Data in R\n\nBefore we dive into some R code, which I do love, it's useful to first understand at a high level how this works. Before you scramble to close this, wait! I promise it isn't going to be technical or boring....or at least I'll try my best to not make it boring.\n\nThe way it works is we first assume a distribution (Gaussian, binomial, etc) that has some important pieces called parameters. You're probably familiar with these for a Gaussian (sometimes called normal distribution), they're the mean and standard deviation. These will determine the shape and probabilities of the distribution. So if we're going to simulate a Gaussian distribution, we need to pick these numbers.\\\n\\\nOnce we have that information we can start picking out random samples. For example, if we know the average age is 60 and the standard deviation is 10, we can pick a person out from this group and find out their age is 78. Now, how do we do this in R?\n\n::: callout-note\n## Time-to-Event Outcome\n\nFor simplicity, we'll categorize outcomes into three categories as continuous, binary or time-to-event (TTE). This post won't tackle TTE outcomes, but a future blog post will! It's slightly more complicated, although nothing too tough to handle! Just would make for too long of a single post.\n:::\n\n### Continuous Outcomes\n\nTo simulate data in R, we can use a family of functions that start with r. For example, if we want to simulate data from a normal distribution we can use the *rnorm* function. Let's simulate an exposure and outcome. But first, we need a question! Our question will be \"Do more pacifiers in a baby's crib cause them to sleep longer?\"\n\nWe also need to decide what types of variables the exposure and the other variable are. Are they continuous, binary or some other type? For simplicity, we'll assume both are variables that have a Gaussian/normal distribution. For our outcomes, it's definitely continuous but how is it related to these other variables? We need an equation! We'll use the following equation (that is completely made up): $\\text{hours slept} = 4 +0.5*\\text{number of pacifiers} + 0.25* \\text{age in months}$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nset.seed(123) # we need to set a seed prior to simulating data. This allows us to replicate the data. For more details check out this blog post: [insert blog post about using different seeds for simulations]\n\nn.babies = 128 # note to get this value I used runif(1, min = 100, max = 500) then picked closest number divisible by 2\n\nnum_pacifiers = rnorm(n = n.babies, mean = 8, sd = 3)\nage_months = rnorm(n.babies, mean = 9, sd = 2)\nhours_slept = 4 + 0.5*num_pacifiers + 0.25*age_months \n\ndf = data.frame(\n  num_pacifiers, \n  age_months,\n  hours_slept\n)\n```\n:::\n\n\nOkay, so we have our data. Now let's do something with it! Let's try fitting a generalized linear model (GLM)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\n\nmod = glm(hours_slept ~ num_pacifiers + age_months, \n          family = gaussian(), # we know this because we simulated the data. In reality, you have to use a combination of visualizing the data, understanding the data generating mechanism (aka what distribution it came from and the best model fit (i.e., Poisson vs negative binomial))\n          data = df \n          )\n\nbroom::tidy(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 Ã— 5\n  term          estimate std.error statistic p.value\n  <chr>            <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)       4     9.15e-16   4.37e15       0\n2 num_pacifiers     0.5   6.22e-17   8.03e15       0\n3 age_months        0.25  8.41e-17   2.97e15       0\n```\n:::\n:::\n\n\nNow, as you can see our estimates were pretty accurate. The intercept is 4, the coefficient for number of pacifiers is 0.5, and the coefficient for age is 0.25. These are exactly right, if we compare them to our equation above. Keep in mind, this makes sense because we included the two variables that we knew affected our outcome (hours slept).\n\nLet's try this again, but this time we'll assume that pacifiers doesn't matter, it's only the age. What will happen if we adjust for both variables still? Let's find out! We'll try two models and compare them. One where we adjust for both variables and one where we adjust for only age.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnum_pacifiers = rnorm(n = n.babies, mean = 8, sd = 3)\nage_months = rnorm(n.babies, mean = 9, sd = 2)\nhours_slept = 4 + 0.5*num_pacifiers + 0.25*age_months \n\ndf = data.frame(\n  num_pacifiers, \n  age_months,\n  hours_slept\n)\n\n# Could alternatively try adjusting for the wrong variable (i.e., pacifiers but not age)\n\nmod1 <- glm(hours_slept ~ age_months, \n            family = gaussian(link = \"identity\"), \n            data = df)\n\nmod2 <- glm(hours_slept ~ age_months + num_pacifiers, \n            family = gaussian(link = \"identity\"), \n            data = df)\n\nsummary(mod1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = hours_slept ~ age_months, family = gaussian(link = \"identity\"), \n    data = df)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  7.85497    0.64176  12.240   <2e-16 ***\nage_months   0.27997    0.06918   4.047    9e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 2.382045)\n\n    Null deviance: 339.15  on 127  degrees of freedom\nResidual deviance: 300.14  on 126  degrees of freedom\nAIC: 478.33\n\nNumber of Fisher Scoring iterations: 2\n```\n:::\n\n```{.r .cell-code}\nsummary(mod2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = hours_slept ~ age_months + num_pacifiers, family = gaussian(link = \"identity\"), \n    data = df)\n\nCoefficients:\n               Estimate Std. Error   t value Pr(>|t|)    \n(Intercept)   4.000e+00  4.115e-15 9.719e+14   <2e-16 ***\nage_months    2.500e-01  3.915e-16 6.386e+14   <2e-16 ***\nnum_pacifiers 5.000e-01  2.519e-16 1.985e+15   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 7.615348e-29)\n\n    Null deviance: 3.3915e+02  on 127  degrees of freedom\nResidual deviance: 9.5192e-27  on 125  degrees of freedom\nAIC: -7919.1\n\nNumber of Fisher Scoring iterations: 1\n```\n:::\n:::\n\n\nNow you see how the impact of adjusting for a variable that doesn't affect the outcome, at least in this case. For our model where we adjust for only age, the result is . When we adjust for the \"correct\" variables , we end up with a coefficient of 0.25.\n\nThis is how you simulate a continuous outcome, but what about a binary outcome?\n\n::: callout-note\n## Continuous Distributions distributions\n\nFor the above example, we used a Gaussian/normal distribution. However, this doesn't need to be the case. If we are dealing with age we may want to use a uniform distribution (using runif) and specifying the minimum and maximum. For example, if we are thinking of a variable where it may not make sense to have a value below a certain value (i.e., age where people are between 18 and 65).\n\nFor simplicity here, and because a number of statistical methods assume normality (*cough* also the central limit theorem *cough*), we will use *rnorm*.\n:::\n\n### Binary Outcomes\n\nSimulating a binary outcome is similar to simulating a continuous outcome. A difference is that we need to convert the linear predictors (our equation) to the scale of choice. To do this, we're going to use the logistic distribution, since we're going to fit a logistic regression later. We can do this using the *plogis* function. Our question this time is \"Does sleeping in a cold room cause a baby to sleep longer?\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn.parents = n.babies*1.5\n\ncoffee_consumption = rnorm(n = n.parents, mean = 3, sd = 0.5)\nhours_baby_slept = rnorm(n = n.parents, mean = 4, sd = 0.25)\ncold_room = rbinom(n = n.parents, size = 1, prob = 0.5)\n\nlinpred = 0.25*hours_baby_slept \n\nprob_tired = plogis(linpred) # converting the linear predictior to a probability on the logistic scale\n\ntired_parents = rbinom(n = n.parents, size = 1, prob = prob_tired)\n\ndf = data.frame(\n  cold_room,\n  coffee_consumption,\n  hours_baby_slept,\n  tired_parents\n)\n```\n:::\n\n\nNow we can fit a logistic regression model!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod = glm(tired_parents ~ hours_baby_slept,\n          # tired_parents ~ coffee_consumption + hours_baby_slept + cold_room,\n          family = binomial(link = \"logit\"), \n          data = df)\n\nsummary(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = tired_parents ~ hours_baby_slept, family = binomial(link = \"logit\"), \n    data = df)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(>|z|)\n(Intercept)        0.1552     2.5939   0.060    0.952\nhours_baby_slept   0.2344     0.6437   0.364    0.716\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 215.94  on 191  degrees of freedom\nResidual deviance: 215.80  on 190  degrees of freedom\nAIC: 219.8\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\nBased on this, we can see that our model doesn't give a great example but if we increase the sample size, what happens? What if we had 10 times the amount of people.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Double check this example (using ChatGPT and another way/blog post/expert)\n\nn.parents.large = n.parents*10\n\ncoffee_consumption = rnorm(n = n.parents.large, mean = 3, sd = 0.5)\nhours_baby_slept = rnorm(n = n.parents.large, mean = 4, sd = 0.25)\ncold_room = rbinom(n = n.parents.large, size = 1, prob = 0.5)\n\nlinpred = 0.25*hours_baby_slept \n\nprob_tired = plogis(linpred)\n\n# linpred = 3 + 0.25*hours_baby_slept + 0.005*cold_room + 0.05*coffee_consumption\n# \n# prob_tired = plogis(linpred)\n  \ntired_parents = rbinom(n = n.parents.large, size = 1, prob = prob_tired)\n\ndf = data.frame(\n  cold_room,\n  coffee_consumption,\n  hours_baby_slept,\n  tired_parents\n)\n\n\nmod = glm(tired_parents ~ hours_baby_slept,\n          # tired_parents ~ coffee_consumption + hours_baby_slept + cold_room,\n          family = binomial(link = \"logit\"), \n          data = df)\n\nsummary(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = tired_parents ~ hours_baby_slept, family = binomial(link = \"logit\"), \n    data = df)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(>|z|)\n(Intercept)       -0.3543     0.8335  -0.425    0.671\nhours_baby_slept   0.3389     0.2087   1.624    0.104\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2236.9  on 1919  degrees of freedom\nResidual deviance: 2234.3  on 1918  degrees of freedom\nAIC: 2238.3\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\nSo if we include 10 times the people, our result gets closer! If we include 100 times the people, we'd expect it to get even closer.\n\n::: callout-note\n## TTE Outcome\n\nAt this point, you may be expecting a section on simulating TTE outcome. This will be the topics of a future blog post, since it's not quite as straight forward as continuous and binary outcomes.\n:::\n\nYou might be thinking \"this is great and all, but how does this apply to causal inference?\"\n\n## Simulating Causal Concepts\n\n## Causal Concepts\n\nThis blog is about causal inference! So let's incorporate some into this post shall we? Instead of looking at GLMs, let's demonstrate how unadjusted confounding can introduce bias. We'll calculate bias as [@morris2019]:\n\n$$\nE[\\hat{\\theta}] - \\theta\n$$\n\nwhere $E[\\hat{\\theta]}$ is the expected, or average, estimated value and $\\theta$ is the \"actual\" value. Later it will make more sense why we're using the average. For now, just keep in mind it's the average of all your estimated values. If you were to repeat this 1000 times, you'd have 1000 coefficients that you estimated and could take the average of those. Alright, let's move along with an example!\n\n::: callout-important\n## Causal Estimand\n\nWe need to make sure we are looking at the same causal estimand when comparing methods. For example, if we want to compare propensity score matching to inverse probability weighting that would result in a different answer...because they target different estimands!\n:::\n\n## Showing Confounding\n\nLet's assume that we want to demonstrate how unadjusted confounding can be problematic. I'm an avid coffee lover, so we'll use an example with coffee! Suppose that our research question is \"Does consuming coffee cause you to be happy?\" We can start by drawing a DAG with our three variables: happy, coffee and sleep.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggdag)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'ggdag'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:stats':\n\n    filter\n```\n:::\n\n```{.r .cell-code}\ntheme_set(theme_dag())\n\ncoffee_dag <- ggdag::dagify(\n  happy ~ coffee + sleep,\n  coffee ~ sleep,\n  exposure = \"coffee\",\n  outcome = \"happy\",\n  labels = c(\n    coffee = \"Coffee\",\n    happy = \"Happiness\",\n    sleep = \"Sleep\"\n  )\n)\n\nggdag::ggdag(coffee_dag, text = FALSE, use_labels = \"label\")\n```\n\n::: {.cell-output-display}\n![](sim_data_files/figure-html/dags-1.png){width=672}\n:::\n:::\n\n\nNow we have our DAG, you might be wondering how this has anything to do with simulating data. Well, it tells you which variables are related, and which ones cause the others. Time to simulate some data!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123) # Setting a seed for reproducibility\n\n# Number of observations\nn <- 1000\n\n# Simulating sleep hours (normal distribution with mean=7 and sd=1.5)\nsleep_hours <- rnorm(n, mean = 7, sd = 1.5)\n\n# Simulating coffee consumption based on sleep (negative correlation: less sleep -> more coffee)\ncoffee_consumption <- 5 - 0.5 * sleep_hours + rnorm(n, mean = 0, sd = 1)\n\n# Simulating happiness based on both sleep (positive correlation: more sleep -> more happiness)\n# and coffee consumption (positive correlation: more coffee -> more happiness)\nhappiness <- rbinom(n = n, size = 1, prob = plogis(0.3 * sleep_hours + 0.2 * coffee_consumption + rnorm(n, mean = 0, sd = 1)))\n\n# Creating a data frame to hold the variables\ndf <- data.frame(sleep_hours, coffee_consumption, happiness)\n\n# Displaying the first few rows of the data\nhead(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  sleep_hours coffee_consumption happiness\n1    6.159287          0.9245580         1\n2    6.654734          0.6326781         1\n3    9.338062          0.3129885         1\n4    7.105763          1.3149436         1\n5    7.193932         -1.1463086         1\n6    9.572597          1.2542747         1\n```\n:::\n:::\n\n\nNow we have our data. To show what happens when you don't adjust for a confounder, we'll fit two models: 1) not adjusting for the confounder, 2) adjusting for the confounder. We know what the \"truth\" is, because we decided it! The \"truth\" is a coefficient of 0.2. Let's see what happens\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod1 <- glm(formula = happiness ~ coffee_consumption,\n            family = binomial(link = \"logit\"),\n            data = df)\n\nmod2 <- glm(formula = happiness ~ coffee_consumption + sleep_hours,\n            family = binomial(link = \"logit\"),\n            data = df)\n\nbias1 = coef(mod1)[2] - 0.2\nbias2 = coef(mod2)[2] - 0.2\n```\n:::\n\n\nNow we have our two models, we can calculate bias for each of these models. As we can see, the bias from model one (-0.1397736) is more than the bias from model two (0.0277288). But how can we trust this? We only did it once. What if a sample of the same size (N = 250) gave a different answer? To account for this, we need to repeat this multiple times. So, let's do that! Let's repeat it a thousand times\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123) # Setting a seed for reproducibility\n\nsimulation <- function() {\n  # Number of observations\n  n <- 250\n  \n  # Simulating sleep hours (normal distribution with mean=7 and sd=1.5)\n  sleep_hours <- rnorm(n, mean = 7, sd = 1.5)\n  \n  # Simulating coffee consumption based on sleep (negative correlation: less sleep -> more coffee)\n  coffee_consumption <- 5 - 0.5 * sleep_hours + rnorm(n, mean = 0, sd = 1)\n  \n  # Simulating happiness based on both sleep (positive correlation: more sleep -> more happiness)\n  # and coffee consumption (positive correlation: more coffee -> more happiness)\n  happiness <- rbinom(n = n, size = 1, prob = plogis(0.3 * sleep_hours + 0.2 * coffee_consumption + rnorm(n, mean = 0, sd = 1)))\n  \n  # Creating a data frame to hold the variables\n  df <- data.frame(sleep_hours, coffee_consumption, happiness)\n  \n  # Building the models\n  mod1 <- glm(formula = happiness ~ coffee_consumption,\n              family = binomial(link = \"logit\"),\n              data = df)\n  \n  mod2 <- glm(formula = happiness ~ coffee_consumption + sleep_hours,\n              family = binomial(link = \"logit\"),\n              data = df)\n  \n  # Calculating the biases\n  coef1 <- coef(mod1)[2] \n  coef2 <- coef(mod2)[2] \n  \n  coef_results <- data.frame(\n    coef1, coef2\n  )\n  \n  # Returning the biases as a named vector\n  return(\n    coef_results\n  )\n}\n\n# Replicating the simulation 1000 times\noutput_list <- replicate(n = 1000, expr = simulation(), simplify = FALSE) \n\n# Bind all data frames in the list into a single data frame\ndf.out <- do.call(rbind, output_list)\n\nbias1 = mean(df.out$coef1) - 0.2\nbias2 = mean(df.out$coef2) - 0.2\n```\n:::\n\n\nRemember the mean from earlier? This is where it comes back up. We'll use the mean of all of these 1000 estimates of our treatment coefficient. So how do they compare, well -0.216 is higher than -0.018 when you look at the absolute value. This is what we'd expect when dealing with a confounder that hasn't been adjusted for.\n\n::: callout-note\n## Picking a number of simulations\n\nFor our example we picked 1000 repetitions but where did this number come from? Truthfully, it was completely arbitrary. In practice, we need to carefully choose how many we need. I highly suggest @morris2019 as a reference for more information if you need to pick the number of simulations.\n:::\n\n# Other Use Cases\n\nWe can use this to show other concepts as well, test new ideas or learn methods ourselves. Recently, I used it to demonstrate to myself the bias when you include a collider. Another example, that I'm currently exploring comparing entropy balancing and inverse probability weighting (in terms of mean squared error, bias, etc). Hopefully you found this post helpful! Would love to hear any situations where you are using simulation. Happy simulating!\n\n## \n",
    "supporting": [
      "sim_data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}