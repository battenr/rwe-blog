{
  "hash": "a02d734dc72559200c38eb709daa6296",
  "result": {
    "markdown": "---\ntitle: \"Collider and Confounder\" # November Post\nsubtitle: \"To Adjust or Not Adjust?\"\nauthor: \"Ryan Batten\"\ndate: \"2023-10-26\"\ncategories: [Collider, Confounder]\nbibliography: collider-confounder.bib\ndraft: true\nformat: \n  html:\n    code-fold: true\n---\n\n\n# Bias if we do, bias if we don't\n\nFor valid causal inference, we need adjust for confounders to block all backdoor paths. If we don't, this can lead to bias. We also need to **not**Â adjust for colliders because that can open a backdoor path. In a perfect world, these two types of variables would never overlap however sometimes a variable is both a collider and a confounder. So what do we do in this case? How can we find a solution?\n\n# Simulate, Simulate, Simulate!\n\nOne way to answer this question is through simulation....which is exactly what we'll do! For this post, we'll just focus on a simple scenario that we can build upon later. With that in mind we need to setup some parameters: what do we want to call the variables,how are these variables related (enter DAG), what types of variables are they (binary, continuous, time-to-event) and how are we going to compare the methods.\n\n# Some Parameters\n\n## Variable Names\n\nLet's come up with some variable names to keep track of things. We'll use X for the exposure/treatment, Y for the outcome and CC for this variable that's both a confounder and a collider (confounder/collider = cc). For the two variables that cause CC, let's call them A and B for simplicity. All of these are arbitrarily chosen names (although X and Y are common conventions for exposure/outcome (and Z for confounders))\n\n## What a Beautiful DAG\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(ggdag)\n\ntheme_set(theme_dag()) # setting the theme \n\ndag = dagify(\n  x ~ cc, \n  y ~ x + cc, \n  cc ~ a + b,\n  exposure = \"x\", \n  outcome = \"y\"\n)\n\ndag |> \n  ggdag(\n    layout = \"nicely\")\n```\n\n::: {.cell-output-display}\n![](collider-and-confounder_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n## Types of Variables\n\nFor this example, we'll assume that A is a binary variable, B is a continuous variable and CC is a continuous variable. Additionally, we'll assume that X is a binary variable (yes/no for treatment) and Y is our continuous outcome variable. These were all arbitrarily chosen and can be changed for other scenarios. For this example, simplicity is key. We can always make it more complicated later.\n\n## Measuring Difference Between Two Methods\n\nFor this scenario, we'll just look at bias. From @morris2019, the equation for bias is:\n\n$$\n\\frac{1} {n_{sim}}\\sum_{i=1}^{n_{sim}}{\\hat{\\theta}_i - \\theta}\n$$\n\nWe'll use the Monte Carlo standard error of the estimate as well (also from @morris2019):\n\n$$\n\\sqrt{\\frac{1} {n_{sim} (n_{sim}-1)}\\sum_{i=1}^{n_{sim}}{(\\hat{\\theta}_i - \\overline{\\theta}})^2}\n$$\n\n# Coding Time!\n\nAlright, let's get into coding!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123) # First setting a seed for reproducibility \n\n# Loading Libraries \n\n\nlibrary(tidyverse)\nlibrary(broom) # for cleaning output of models \n\nn = 430 # setting our sample size \n\na = rbinom(n = n, size = 1, prob = 0.46) # Simulating A from a binomial distribution\nb = rnorm(n = n, mean = 5, sd = 2) # Simulating B from a normal distribution\ncc = 0.7*a + 0.3*b #assuming that CC is caused by both A and B \n\nx = rbinom(n = n, size = 1, prob = plogis(0.1*cc)) # Simulating X from a binomial distribution that is caused by CC\ny = rnorm(n = n) + 0.2*cc + 0.4*x # Assuming Y is caused by CC and X\n\ndf = data.frame(\n  a, \n  b, \n  cc, \n  x, \n  y\n)\n\nmod.adj <- glm(y ~ x + cc, \n               family = gaussian(link = \"identity\"), \n               data = df)\n\ncoeff.adj = broom::tidy(mod.adj)[2,2]\n\nmod.unadj <- glm(y ~ x, \n               family = gaussian(link = \"identity\"), \n               data = df)\n\ncoeff.unadj = broom::tidy(mod.unadj)[2, 2]\n```\n:::\n\n\nNow we can see how they'd be different. Let's look at both estimates. For the adjusted model we have 0.4195327 and for the unadjusted model we have 0.4206856. This is only after running it one time though! We need to re-run it more than once though. To do this, we can put our code from before into a function.\n\n## Making Code Functional (Pun Intended!)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# We'll make a function that we can specifc the treatment effect, the strength of the confounder (on the outcome and exposure. Assuming that it affects both equally, which could also be changed/examind)\n\nsim_col_con <- function(trt_effect, \n                        con_effect,\n                        n.sample){\n  \n  # \n  \n  a = rbinom(n = n.sample, size = 1, prob = 0.46)\n  b = rnorm(n = n.sample, mean = 5, sd = 2)\n  cc = 0.5 + 0.7*a + 0.3*b\n  \n  x = rbinom(n = n.sample, size = 1, prob = plogis(con_effect*cc))\n  y = 3 + con_effect*cc + trt_effect*x + rnorm(n = n.sample, mean = 0, sd = 1)\n  \n  df = data.frame(\n    a, \n    b, \n    cc, \n    x, \n    y\n  )\n  \n  # Adjusting for variable\n  \n  mod.adj <- glm(y ~ x + cc, \n                 family = gaussian(link = \"identity\"), \n                 data = df)\n  \n  adj.trt.effect <- broom::tidy(mod.adj)$estimate[2]\n  \n  # Not adjusting for variable \n  \n  mod.unadj <- glm(y ~ x, \n                   family = gaussian(link = \"identity\"), \n                   data = df)\n  \n  unadj.trt.effect <- broom::tidy(mod.unadj)$estimate[2]\n  \n  df.trt.effects <- data.frame(\n    adj.trt.effect,\n    unadj.trt.effect\n  )\n  \n  return(\n    df.trt.effects\n  )\n  \n}\n```\n:::\n\n\nGreat now we have our function! Let's do it a bunch of times.\n\n## Repeat, Repeat, Repeat\n\nFor this quick example, we'll repeat it 1000 times. In reality, more thought should go into the number of simulations required. I would suggest @morris2019 for more details regarding that. For now, let's proceed with 1000.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Repeating 1000 times ----\n\noutput_list <- replicate(1000, sim_col_con(0.4, 0.3, n.sample = 430), simplify = FALSE)\n\n# Bind all data frames in the list into a single data frame\ndf.out <- do.call(rbind, output_list)\n```\n:::\n\n\nGreat! Now we have our simulations, time to start calculating some results!\n\n## Bias and SE of Bias\n\nWe'll calculated the estimated bias and the Monte Carlo standard error of the bias.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Bias \n\nbias.adjust = round((1/430)*sum(df.out$adj.trt.effect - 0.4),3)\n\nbias.unadjust = round((1/430)*sum(df.out$unadj.trt.effect - 0.4),3)\n\n# SE of the bias \n\nse.adjust = round((1/(429*430)) * sum((df.out$adj.trt.effect - mean(df.out$adj.trt.effect))^2),3)\n\nse.unadjust = round((1/(429*430)) * sum((df.out$unadj.trt.effect - mean(df.out$unadj.trt.effect))^2),3)\n\nresults.adjust = paste0(bias.adjust, \" (\", se.adjust, \")\")\n  \n  \n  \nresults.unadjust = paste0(bias.unadjust, \" (\", se.unadjust, \")\")\n```\n:::\n\n\nGreat! Now let's interpret these results. For adjusted estimate, its -0.002 (0) and for the unadjusted estimate its 0.101 (0)\n\n# So...do we adjust or not?\n\nBased on our simple example, my takeaway would be to adjust for the confounder even if it is a collider. However...and a big however...this is under a lot of circumstances that we could build upon. What if both A and B were continuous? What if they were both binary? What if the outcome were binary? What if CC was binary? These are just a few places to start. The good news is that we have the simple scenario covered so we can easily try out these out scenarios and see what we'd do!\n\n# Next Steps\n\nThis post was just meant to be a starting point. If you're interested in different scenarios, I'd recommend you try altering pieces of the code and see how that impacts the results! If you're new to simulating data, I'd also recommend perhaps starting with another post on my blog ([Simulating Data](https://causallycurious.com/posts/simulating-data/sim_data)).\\\n\\\nIf you do expand on this or have any ideas about it, I'd love to hear about them (either through email or [LinkedIn](https://www.linkedin.com/in/rwe-ryan/)). Happy exploring!\n",
    "supporting": [
      "collider-and-confounder_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}